{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xx8sqdBs6TDE"
   },
   "source": [
    "# Método de la Potencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xx8sqdBs6TDE"
   },
   "source": [
    "En muchas aplicaciones del mundo real de la ciencia y la ingeniería, se requiere encontrar numéricamente el valor Eigen más grande o dominante y el Eigenvector correspondiente. Existen diferentes como el método de la potencia que sigue un enfoque iterativo y conforma un algoritmo simple.\n",
    "\n",
    "El siguiente algoritmo busca desarrollar los pasos necesario para el método de la potencia y así después pues ser implementado como otro método alternativo a los demás que se tienen en el proyecto.\n",
    "\n",
    "Dada una matriz $A$ diagonalizable, el algoritmo de la potencia genera un número $\\lambda$ que es el eigenvalor más grande (en valor asoluto) de $A$, y un vector no nulo $v$, que es el eigenvector correspondiente a $\\lambda$, es decir, son tales que $Av = \\lambda v$.\n",
    "\n",
    "El método de la potencia comienza con un vector $b_0$, que puede ser un vector aleatoio, o bien una aproximación al eigenvector dominante. La relación de recurrencia que describe al método es:\n",
    "$$b_{k+1}= \\frac{Ab_k}{\\|Ab_k\\|}$$\n",
    "Por lo que, en cada iteración, el vector $b_k$ es multiplicado por la matriz $A$ y luego normalizado.\n",
    "\n",
    "Buscamos una sucesión $(b_k)$ que converja a un eigenvector Para asegurar la convergencia, necesitan cumplirse las siguientes condiciones:\n",
    "\n",
    "- $A$ tiene un eigenvalor estrictamente mayor en magnitud respecto a sus otros eigenvalores\n",
    "- El vector de inicio $b_0$ tiene una componente distinta de cero en la dirección de un eigenvector asociado con el eigenvalor dominante.\n",
    "\n",
    "Además, bajo las dos supoosiciones anteriores, la sucesión $(\\mu_k)$ definida por:\n",
    "$$\\mu_k = \\frac{b_k^TAb_k}{b_k^Tb_k}$$\n",
    "converge al eigenvalor dominante. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "text",
    "id": "Xx8sqdBs6TDE"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/nndb_flat.csv', encoding = \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "text",
    "id": "Xx8sqdBs6TDE"
   },
   "outputs": [],
   "source": [
    "df.drop(df.columns[df.columns.str.contains('_USRDA')].values, \n",
    "        inplace=True, axis=1)\n",
    "df = df.drop(columns=['ID','FoodGroup','ShortDescrip','Descrip','CommonName','MfgName','ScientificName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "text",
    "id": "Xx8sqdBs6TDE"
   },
   "outputs": [],
   "source": [
    "####Se estandarizan los datos.\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.89623357, -1.01174721,  4.44128945, ..., -0.64991809,\n",
       "        -0.41055694, -0.55991833],\n",
       "       [ 2.89623357, -1.01174721,  4.44128945, ..., -0.65484222,\n",
       "        -0.41055694, -0.57183012],\n",
       "       [ 3.83495634, -1.06577576,  5.59915265, ..., -0.75332487,\n",
       "        -0.44590424, -0.58374191],\n",
       "       ...,\n",
       "       [ 0.25127886, -1.0923161 , -0.67108312, ..., -0.72870421,\n",
       "        -0.42116113, -0.53013886],\n",
       "       [-0.80552224,  0.43375349, -0.58284096, ...,  0.57126681,\n",
       "         0.52261173, -0.28892514],\n",
       "       [-0.81142615,  0.78446513, -0.63956806, ...,  0.11824661,\n",
       "         0.14793037, -0.28892514]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "text",
    "id": "Xx8sqdBs6TDE"
   },
   "outputs": [],
   "source": [
    "# Matriz de Covarianzas\n",
    "C = np.dot(X.T, X)/X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función que implementa el método de la potencia para obtener el eigenvalor dominante y su correspondiente eigenvector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "text",
    "id": "Xx8sqdBs6TDE"
   },
   "outputs": [],
   "source": [
    "def power_iteration(A, num_simulations: int):\n",
    "    # Ideally choose a random vector\n",
    "    # To decrease the chance that our vector\n",
    "    # Is orthogonal to the eigenvector\n",
    "    b_k = np.random.rand(A.shape[1])\n",
    "\n",
    "    for _ in range(num_simulations):\n",
    "        # calculate the matrix-by-vector product Ab\n",
    "        b_k1 = np.dot(A, b_k)\n",
    "\n",
    "        # calculate the norm\n",
    "        b_k1_norm = np.linalg.norm(b_k1)\n",
    "\n",
    "        # re normalize the vector\n",
    "        b_k = b_k1 / b_k1_norm\n",
    "    \n",
    "    #Obtenemos el eigenvalor correspondiente a b_k con el cociente de Rayleigh\n",
    "    m_k = (b_k.T@A@b_k)/(b_k.T@b_k)\n",
    "    \n",
    "    #Devolvemos el mayor eigenvalor y su correspondiente eigenvector\n",
    "    return m_k,b_k\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_1,b_1 = power_iteration(C,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.449285764311568"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eigenvalor dominante\n",
    "m_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15781363, 0.1406199 , 0.03300812, 0.16968451, 0.07632275,\n",
       "       0.18156988, 0.13351884, 0.31566282, 0.17798456, 0.08763937,\n",
       "       0.13712201, 0.28410233, 0.33777895, 0.34132464, 0.27245318,\n",
       "       0.16811197, 0.18080591, 0.2998569 , 0.24134847, 0.09356749,\n",
       "       0.19940258, 0.0923186 , 0.24355123])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eigenvector correspondiente al eigenvalor dominante\n",
    "b_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comparar los valores obtenidos con el primer eigenvalor y eigenvector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalues, evectors = np.linalg.eig(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.449285764311579"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalues[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.15781363, -0.1406199 , -0.03300812, -0.16968451, -0.07632275,\n",
       "       -0.18156988, -0.13351884, -0.31566282, -0.17798456, -0.08763937,\n",
       "       -0.13712201, -0.28410233, -0.33777895, -0.34132464, -0.27245318,\n",
       "       -0.16811197, -0.18080591, -0.2998569 , -0.24134847, -0.09356749,\n",
       "       -0.19940258, -0.0923186 , -0.24355123])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evectors.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(m_1,evalues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(np.abs(b_1),np.abs(evectors.T[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xx8sqdBs6TDE"
   },
   "source": [
    "## Deflation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xx8sqdBs6TDE"
   },
   "source": [
    "Con lo anterior, hemos obtenido el eigenvalor de mayor magnitud y su correspondiente eigenvalor. Sin embargo, para hacer el PCA necesitamos los demás eigenvalores. Es aquí donde entra el método de *deflation*. Este consiste en volver a aplicar el método a una matriz actualizada:\n",
    "$$A_{k+1}= A_k - b_kb_k^TA_kb_kb_k^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xx8sqdBs6TDE"
   },
   "source": [
    "Apliquemos dicha transformación a la matriz de covarianzas $C$ para obtener el segundo eigenvalor de $C$ y su correspondiente eigenvector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_def = C- np.outer(b_1,b_1)@C@np.outer(b_1,b_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_2,b_2 = power_iteration(C_def,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6184583526663694"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.27344866, -0.34339677,  0.11167035,  0.44341644,  0.35876913,\n",
       "        0.25773287, -0.23647025, -0.02112889, -0.35504461,  0.03852455,\n",
       "        0.10637166,  0.09709328, -0.08480073, -0.07347102,  0.0751503 ,\n",
       "        0.10517259, -0.21266898,  0.09381195,  0.10336119, -0.08878313,\n",
       "       -0.08744763, -0.23932243, -0.17779772])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos corroborar que estos valores aproximan el segundo eigenvalor y su correspondiente eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6184583526663796"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalues[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.27344866,  0.34339677, -0.11167035, -0.44341644, -0.35876913,\n",
       "       -0.25773287,  0.23647025,  0.02112889,  0.35504461, -0.03852455,\n",
       "       -0.10637166, -0.09709328,  0.08480073,  0.07347102, -0.0751503 ,\n",
       "       -0.10517259,  0.21266898, -0.09381195, -0.10336119,  0.08878313,\n",
       "        0.08744763,  0.23932243,  0.17779772])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evectors.T[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, creamos una función que combine el método de la potencia y *deflation*:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_deflation(A,iter):\n",
    "    #numero de columnas\n",
    "    n = A.shape[1]\n",
    "    # Inicializamos arrays de ceros\n",
    "    eigenvalues = np.zeros(n)\n",
    "    eigenvectors = np.zeros((n,n))\n",
    "    #Hago una copia de la matriz original\n",
    "    A_def = A.copy()\n",
    "    #Iteramos tantas veces como columnas de la matriz\n",
    "    for i in range(n):\n",
    "        #Aplicamos el método de la potencia\n",
    "        m_def,b_def = power_iteration(A_def,iter)\n",
    "        #Actualizamos los arrays de eigen valores y vectores\n",
    "        eigenvalues[i] = m_def\n",
    "        eigenvectors[:,i]= b_def\n",
    "        # Matriz actualizada\n",
    "        A_def = A_def - np.outer(b_def,b_def)@A_def@np.outer(b_def,b_def)\n",
    "    return eigenvalues, eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalues_pow, evectors_pow = power_deflation(C,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos notar que (salvo por el orden decreciente en que nosotros obtenemos los valores), se trata de una buena aproximación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.44928576e+00, 2.61845835e+00, 2.03189746e+00, 1.87912807e+00,\n",
       "       1.63567543e+00, 1.14036709e+00, 1.06087106e+00, 9.26189477e-01,\n",
       "       8.61952843e-01, 8.24826963e-01, 7.31232602e-01, 5.96894949e-01,\n",
       "       5.08479245e-01, 4.69648488e-01, 4.07987975e-01, 3.35026344e-01,\n",
       "       3.31768786e-01, 3.22018315e-01, 2.56187042e-01, 2.38154652e-01,\n",
       "       2.11160240e-01, 1.59093679e-01, 3.79524723e-03])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lo que obtenemos\n",
    "evalues_pow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.44928576e+00, 2.61845835e+00, 2.03189759e+00, 1.87913144e+00,\n",
       "       1.63567140e+00, 1.14037066e+00, 1.06086727e+00, 9.26253795e-01,\n",
       "       8.62018168e-01, 8.24686441e-01, 7.31232556e-01, 5.96894964e-01,\n",
       "       5.08653057e-01, 4.69461661e-01, 4.07986316e-01, 3.37934003e-01,\n",
       "       3.29568690e-01, 3.21238326e-01, 2.56202403e-01, 2.38139303e-01,\n",
       "       2.11158912e-01, 1.59093679e-01, 3.79524723e-03])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lo que esperamos (ordenado de forma decreciente)\n",
    "evalues = np.sort(evalues)[::-1]\n",
    "evalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "colab_type": "code",
    "id": "wy8DD4cgT2b5",
    "outputId": "2d43eec0-f64d-4596-e147-a1894d524b5a"
   },
   "outputs": [],
   "source": [
    "def PCA_from_potencia(X):\n",
    "    prop = 0 #Proporción de varianza explicada\n",
    "    comp = 1 \n",
    "    cur_var = 0\n",
    "    comp_vecs = np.zeros([X.shape[1], X.shape[1]])\n",
    "    \n",
    "    # convertir a array\n",
    "    A = np.array(X)\n",
    "    \n",
    "    # Centrar los datos\n",
    "    mean_vec = np.mean(A, axis=0)\n",
    "    datos_centrados = (A - mean_vec)\n",
    "    \n",
    "    #Calculamos la matriz de covarianzas\n",
    "    cov = np.dot(X.T, X)/X.shape[0]\n",
    "    \n",
    "    #Aplicamos el método de la potencia\n",
    "    evalues_pow, evectors_pow = power_deflation(cov,50)\n",
    "    \n",
    "    # La varianza explicada\n",
    "    varianza_explicada = evalues_pow/np.sum(evalues_pow)\n",
    "    \n",
    "    # Los datos transformados (componentes principales)\n",
    "    Z = datos_centrados@evectors_pow\n",
    "    \n",
    "    \n",
    "    # Calcula número de componentes de manera automatica de acuerdo a la variana explicada\n",
    "    # Threshold de 80%\n",
    "    n = X.shape[1] #numero de columnas\n",
    "    varianza_acumulada = varianza_explicada.cumsum()\n",
    "    conteo = (varianza_acumulada)  <  0.8\n",
    "    num_componentes = conteo.sum() + 1\n",
    "    \n",
    "    return evalues_pow[:num_componentes], evectors_pow[:num_componentes], Z[:,:num_componentes], varianza_explicada[:num_componentes] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, componentes, Z, var_explicada = PCA_from_potencia(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.44928576, 2.61845835, 2.0318866 , 1.8791433 , 1.63567143,\n",
       "       1.14037024, 1.06086173, 0.9259546 , 0.86107886, 0.82600963])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15781363, -0.27343437,  0.46244017,  0.04813368,  0.29358612,\n",
       "         0.13270953,  0.06666283,  0.07717095,  0.06127852, -0.13225757,\n",
       "        -0.13979036,  0.11710477, -0.05756254, -0.06707062,  0.03933277,\n",
       "         0.06923014, -0.09501888, -0.04719535,  0.08541941,  0.06795423,\n",
       "        -0.12889147, -0.03809124, -0.67801123],\n",
       "       [ 0.1406199 ,  0.34340328,  0.2109066 , -0.31306212, -0.01305824,\n",
       "         0.14145138,  0.00590418,  0.12625714,  0.14083793,  0.00741331,\n",
       "        -0.30697748, -0.12972777, -0.31117387,  0.08437973, -0.13236093,\n",
       "         0.13908246,  0.00315365,  0.49869381,  0.06022338,  0.22226724,\n",
       "        -0.2536767 , -0.10876264,  0.1789299 ],\n",
       "       [ 0.03300812, -0.11165384,  0.53425612,  0.02174598,  0.39445097,\n",
       "        -0.11659471,  0.04534104, -0.0560572 , -0.04948317, -0.21370583,\n",
       "        -0.05339109,  0.20191276,  0.10427672, -0.10183696,  0.03322662,\n",
       "        -0.08718438,  0.22193676, -0.01895494, -0.09335814, -0.04616235,\n",
       "         0.15878048,  0.03670126,  0.56327959],\n",
       "       [ 0.16968451, -0.44341793, -0.04832415,  0.1745314 , -0.08278709,\n",
       "         0.27931338,  0.02175983,  0.16314395,  0.09629047,  0.06280318,\n",
       "        -0.02618123, -0.02832133, -0.11310627, -0.0101279 ,  0.09300322,\n",
       "         0.15840523, -0.42543669, -0.24247076,  0.22048415,  0.07088712,\n",
       "        -0.2793357 , -0.06792167,  0.43587131],\n",
       "       [ 0.07632275, -0.35877078, -0.05338728,  0.21788613,  0.04834018,\n",
       "         0.33633086,  0.29851216,  0.1570585 ,  0.06663478,  0.40685275,\n",
       "        -0.08064353, -0.22800755,  0.02153747,  0.11540084, -0.13901091,\n",
       "        -0.12227296,  0.34836687,  0.2799526 , -0.23220386, -0.05579058,\n",
       "         0.21125838,  0.07926232, -0.0029982 ],\n",
       "       [ 0.18156988, -0.25773161,  0.04076789,  0.0416522 , -0.33217591,\n",
       "        -0.13392086, -0.41632068,  0.17940058, -0.06188962, -0.10058097,\n",
       "         0.04646721,  0.09920034, -0.26522561, -0.0542155 ,  0.53583732,\n",
       "        -0.02770692,  0.13603952,  0.33436597, -0.03035129, -0.04638555,\n",
       "         0.19178416,  0.06854926, -0.02738352],\n",
       "       [ 0.13351884,  0.23647107,  0.02641853,  0.53016915, -0.00833009,\n",
       "        -0.03925948,  0.10154586, -0.04723004,  0.00328477, -0.11922116,\n",
       "         0.03145004,  0.07850414, -0.10389611, -0.1081088 , -0.08137239,\n",
       "        -0.46376465, -0.38770354,  0.30737169, -0.15885177, -0.26369648,\n",
       "        -0.17718799,  0.02839376,  0.00168609],\n",
       "       [ 0.31566282,  0.02112346, -0.17561412, -0.11272315,  0.13378557,\n",
       "        -0.20058331,  0.02364356,  0.08542218, -0.01970047,  0.19719412,\n",
       "        -0.05793625,  0.00894997, -0.35166377, -0.30900825,  0.00772523,\n",
       "        -0.37249926,  0.13944538, -0.34329485, -0.23451638,  0.31082336,\n",
       "        -0.0343218 , -0.31321715, -0.00614935],\n",
       "       [ 0.17798456,  0.3550451 ,  0.01568457,  0.3464373 ,  0.0587304 ,\n",
       "         0.12301999,  0.05632301, -0.00376747, -0.15436241,  0.1056543 ,\n",
       "         0.06159317,  0.071348  , -0.21490031,  0.01833931,  0.21632044,\n",
       "         0.45593183,  0.34357467, -0.24978526, -0.17471031, -0.15017605,\n",
       "        -0.29046714,  0.20656095,  0.00364661],\n",
       "       [ 0.08763937, -0.03852955, -0.16189125,  0.04906289, -0.02473326,\n",
       "        -0.54626969,  0.44649453,  0.52351771,  0.07487112, -0.14577674,\n",
       "        -0.11490482,  0.07681111,  0.21144109,  0.00981341,  0.03355362,\n",
       "         0.26221971, -0.06443985,  0.09638222, -0.09998095,  0.0566858 ,\n",
       "        -0.02203939,  0.0370972 , -0.00533693]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "componentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.12177585e+00, -1.18213797e+00,  3.67098479e+00, ...,\n",
       "        -5.98229058e-01, -3.07553933e-01, -1.50894797e+00],\n",
       "       [-1.11468691e+00, -1.18405956e+00,  3.67145779e+00, ...,\n",
       "        -5.96024041e-01, -3.16549964e-01, -1.51673776e+00],\n",
       "       [-9.94919411e-01, -1.57343402e+00,  4.70874213e+00, ...,\n",
       "        -5.87928030e-01, -3.22616373e-01, -1.85540140e+00],\n",
       "       ...,\n",
       "       [-7.67670698e-01, -3.26768624e+00, -9.68622209e-01, ...,\n",
       "         8.34093206e-01,  4.17901563e-01,  2.06187652e+00],\n",
       "       [ 3.55897094e-01,  6.78466168e-01,  9.97247069e-01, ...,\n",
       "         6.62557619e-01, -5.47727873e-02,  1.06179821e-01],\n",
       "       [-8.66889802e-01,  1.19845293e+00, -1.97560729e-01, ...,\n",
       "        -2.49720128e-01, -6.41314855e-02,  4.44507507e-04]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2369236 , 0.11384512, 0.0883422 , 0.08170124, 0.07111559,\n",
       "       0.04958092, 0.04612406, 0.04025858, 0.03743792, 0.03591318])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_explicada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "- Wikipedia [Power iteration](https://en.wikipedia.org/w/index.php?title=Power_iteration&oldid=957783806) (last visited May 29, 2020)\n",
    "- Mackey, Lester. (2008). Deflation Methods for Sparse PCA. Advances in Neural Information Processing Systems 21 - Proceedings of the 2008 Conference. 21. 1017-1024. \n",
    "- Power Method Algorithm for Finding Dominant Eigen Value and Eigen Vector. (n.d.). Retrieved May 23, 2020, from https://www.codesansar.com/numerical-methods/power-method-algorithm-for-finding-dominant-eigen-value-and-eigen-vector.htm\n",
    "\n",
    "- Fox, J., Chalmers, P., Monette, G., & Sanchez, G. (2020, April 14). powerMethod: Power Method for Eigenvectors in matlib: Matrix Functions for Teaching and Learning Linear Algebra and Multivariate Statistics. Retrieved from https://rdrr.io/cran/matlib/man/powerMethod.html\n",
    "\n",
    "- Dan, D. J. (n.d.). dianejdan/Power-Method-PCA. Retrieved May 27, 2020, from https://github.com/dianejdan/Power-Method-PCA/blob/master/power-pca.py"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Metodo_de_la_potencia.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
